
\todo{talk about similar control schemas} % RL, LCS and MDP


\chapter{Related Work} \label{ch:related_works}
Recent advances in hardware capabilities and computational intelligence techniques have led to the introduction of robotics in numerous complex use cases.
Robotic agents continue to phase out human agents for tasks that are considered mundane or dangerous, or simply because a machine can provide better results for less cost.
Here we focus on the application of autonomous robots in exploration-based operations.
Examples of these operations are exploration-based scientific research, and search and rescue settings. \todo{more specific examples}
These types of operations have shown promising boosts in performance through the use of autonomous agents for a few reasons.
Most notably, there are typically certain levels of hazard involved in exploration, and search and rescue that limit or prevent a human agent's performance.
In the majority of cases, a robotic agent is less susceptible to the same environmental hazards as a human.
Use of robotics can help eliminate the risk of injury, disease and death of humans involved in an operation.
The other advantages to using autonomous robots is the diverse number of sensors that a robotic agent can use, as well as their ability to analyze data quickly and without bias.
Sensors, such as an infrared camera, can accurately collect data that humans do not have the capability to observe themselves.
Large amounts of sensor data can also be processed and analyzed by a computer more efficiently than a human.
This supports the idea that a robotic agent can operate at higher performance levels than a human could in many exploration-based operations.

% Use of autonomous robots in exploration settings
There is an abundant amount of existing research on the use of autonomous robots for exploration.
Both intelligent hardware and software approaches have been researched to create robotic agents that can safely and efficiently navigate an environment.
Many of the hardware focused solutions explore clever designs for mobility features that enable them to traverse hazardous and complex environments \todo{hardware refs}.
Software solutions typically focus on the application of AI control schemas to plan hazard avoidance, and maximize efficiency~\cite{christensen_multi-robot_2017, tai_autonomous_2017, stachniss_exploration_2004, clark_mobile_2007, perea_strom_robust_2017, fink_tier-scalable_2007, bai_toward_2017}.
Each of these autonomous exploration-based research experiments share three key components: there is a robotic agent with a set of actions that it can performed, the agent must use intelligence to navigate their environment, and the agent is goal driven.
While these components are present in all of these experiments, there is a large variation in the use cases and control schemas.
Some are designed for mapping indoor or outdoor environments~\cite{tai_autonomous_2017,  stachniss_exploration_2004, perea_strom_robust_2017}, others focus on hazard avoidance~\cite{christensen_multi-robot_2017, fink_tier-scalable_2007}, and some use multiple agents working together \cite{christensen_multi-robot_2017, clark_mobile_2007}, and some focus on operation efficiency \cite{bai_toward_2017}.
A variety of intelligent approaches for controlling the agents range from the use of Bayesian prediction models~\cite{christensen_multi-robot_2017}, artificial neural networks~\cite{tai_autonomous_2017} and machine learning~\cite{bai_toward_2017} to name a few.
Each of these experiments focused on AI controllers that were hand crafted for a specific goal.
The SCOUt project aims to address all of these use cases for autonomous agents in a unified operation setup process and adaptive control schema.
% \cite{christensen_multi-robot_2017} Multi-robots in hazardous areas; Use Bayesian prediction model to avoid hazards.
% \cite{tai_autonomous_2017} Indoor exploration in unknown environment using a Convolutional Neural Network.
% \cite{stachniss_exploration_2004} Combination of autonomous exploration with localization mapping.
% \cite{clark_mobile_2007} Multi-robot perimeter detection.
% \cite{perea_strom_robust_2017} Exploring and mapping unknown environments.
% \cite{fink_tier-scalable_2007} Example robotics mission that requires exploration in hazardous environments.
% \cite{bai_toward_2017} Uses supervised learning for autonomously exploration with efficient user of a single sensor.

While preliminary research did not uncover any existing work on a unified process for the setup and control of exploration-based operations, the idea of a single adaptive controller for completing multiple goals is not a new concept.
Arora et al.~\cite{arora_approach_2017, hutter_online_2018} have created control schemas that are both adaptive to an agent's capabilities, as well as a diversity of environments.
In their research conducted in 2017~\cite{arora_approach_2017}, they use a high-level approach to generate a controller that can model and analyze scientific data in a task-based approach across multiple goals.
Their later research in 2018~\cite{hutter_online_2018} achieves efficient path planning and sensor usage policies through an adaptive Bayesian framework.
% \cite{arora_approach_2017} Use of on board systems to model scientific data and reason path/action planning.
% \cite{hutter_online_2018} Exploration and sensor planning for scientific missions.
SCOUt exhibits similar functionality through its use of a memory-based reinforcement learning model to plan actions that will maximize goal completion and minimize damage and energy usage for a variety of operations.
Memory based control schemas have been used in existing experiments for decision-based models.
Experiments such as~\cite{fu_genetic_2003, yi_new_2011}, used a genetic algorithm (GA) to generate decision policies through the use of existing knowledge.
Arulkumaran et al.~\cite{arulkumaran_brief_2017} cover an approach to handling large memory sets, as large pools of memory can yield more accurate results but lead to the issues with increased complexity and storage requirements.
There has also been a heavy use of reinforcement learning in the field of robotics.
Specifically, \cite{arulkumaran_brief_2017, bai_toward_2017, kiumarsi_optimal_2018} all implement reinforcement based learning for action decision models.
SCOUt's decision schema follows a similar model to \cite{kiumarsi_optimal_2018}, using an adaptive process for choosing actions by applying a score system for predicting and critiquing the performance of agents within an environment.
% \cite{arulkumaran_brief_2017} Discusses the use of Deep Reinforcement Learning for "experience-driven autonomous learning", pairing with robotics and the challenges related to the complexity of memory, sampling and computation.
% \cite{fu_genetic_2003} GA approach to decision tree building for intelligent action pattern building.
% \cite{yi_new_2011} Another GA approach to decision tree building.
% \cite{kiumarsi_optimal_2018} Very similar action reward system for machine learning using actor -> environment -> critique -> reward.
